#!/usr/bin/env python3
# filename: wizard_bot.py
import os, asyncio, logging, time, io, re, json, atexit
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Tuple
from PIL import Image
from telegram import Update, File
from telegram.constants import ChatType, MessageEntityType, ParseMode
from telegram.error import BadRequest
from telegram.ext import (
    ApplicationBuilder, ContextTypes,
    CommandHandler, MessageHandler, filters, CallbackContext
)
import google.generativeai as genai
from google.generativeai.types import GenerationConfig, ContentType, PartType, Tool, FunctionCall
from flask import Flask, render_template_string
import threading
import requests

# –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ Flask-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞
flask_app = Flask(__name__)

# HTML-—à–∞–±–ª–æ–Ω –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400;700&family=Space+Mono:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://xn--80aqtedp.xn--p1ai/skibidicss">
    <link href="https://unpkg.com/aos@2.3.1/dist/aos.css" rel="stylesheet">
    <title>—â–∞—Å –≤—Å—ë –∑–∞—Ä–∞–±–æ—Ç–∞–µ—Ç, —Å–ª–æ–≤–æ –ø–∞—Ü–∞–Ω–∞</title>
    <link rel="icon" href="https://xn--80aqtedp.xn--p1ai/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="hero">
        <div class="hero-content">
            <h1>–ë—Ä–æ, —è –∑–∞–ø—É—Å—Ç–∏–ª—Å—è</h1>
            <p>–ï—Å–ª–∏ —è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–Ω—è–ª, —Ç–æ –±–æ—Ç –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –µ—â—ë 15 –º–∏–Ω—É—Ç, –µ—Å–ª–∏ —Ç–µ–±–µ –ø—Ä–∏—à–ª–æ—Å—å –ø–æ—Å–µ—Ç–∏—Ç—å —ç—Ç–æ—Ç —Å–∞–π—Ç, –∞ –µ—Å–ª–∏ –æ–Ω –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∏ –±–æ–ª—å—à–µ, –∑–Ω–∞—á–∏—Ç —Ç–µ–±–µ –µ–≥–æ –∏ –Ω–µ –Ω–∞–¥–æ –±—ã–ª–æ –ø–æ—Å–µ—â–∞—Ç—å.\n</p>
            <div class="tenor-gif-embed" data-postid="13327394754582742145" data-share-method="host" data-aspect-ratio="1" data-width="100%">
                <a href="https://tenor.com/view/cologne-wear-i-buddy-home-gif-13327394754582742145">Cologne Wear GIF</a>
                from <a href="https://tenor.com/search/cologne-gifs">Cologne GIFs</a>
            </div>
            <script type="text/javascript" async src="https://tenor.com/embed.js"></script>
            <br>
            <a href="https://xn--80aqtedp.xn--p1ai/" target="_blank" class="button-link">–°–∞–π—Ç —Å–æ–∑–¥–∞—Ç–µ–ª–µ–π</a>
        </div>
    </div>
</body>
</html>
"""


@flask_app.route('/')
def home():
    return render_template_string(HTML_TEMPLATE)

# ---------- –ü–æ–ª–∏—Ç–∏–∫–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ ----------
PRIVACY_POLICY_TEXT = """
<b>–ü–æ–ª–∏—Ç–∏–∫–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –°–∏–≥–º–æ–∏–¥–∞</b>

‚ö†Ô∏è <b>–í–∞–∂–Ω–æ:</b> –í–∞—à–∏ —Å–æ–æ–±—â–µ–Ω–∏—è, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –¥—Ä—É–≥–∏–µ –º–µ–¥–∏–∞—Ñ–∞–π–ª—ã, –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —ç—Ç–æ–º—É –±–æ—Ç—É, –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –≤ Google Gemini API –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –±–æ—Ç–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤.
–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —á–∞—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ JSON-—Ñ–∞–π–ª–∞—Ö –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥–∞ –º–µ–∂–¥—É –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–º–∏.
–ò—Å–ø–æ–ª—å–∑—É—è –±–æ—Ç–∞, –≤—ã —Å–æ–≥–ª–∞—à–∞–µ—Ç–µ—Å—å —Å –ø–µ—Ä–µ–¥–∞—á–µ–π –¥–∞–Ω–Ω—ã—Ö –≤ Google –¥–ª—è –∏—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ.

<b>–°–æ–≥–ª–∞—Å–∏–µ:</b> –ü—Ä–æ–¥–æ–ª–∂–∞—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ—Ç–∞ –≤ –ª–∏—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª—è—è —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –±–æ—Ç—É –≤ –≥—Ä—É–ø–ø–æ–≤—ã—Ö —á–∞—Ç–∞—Ö, –≤—ã –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç–µ —Å–≤–æ–µ —Å–æ–≥–ª–∞—Å–∏–µ —Å –¥–∞–Ω–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–æ–π. –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—ã –≥—Ä—É–ø–ø–æ–≤—ã—Ö —á–∞—Ç–æ–≤ –Ω–µ—Å—É—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ –∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –æ —Ç–æ–º, —á—Ç–æ –∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è –º–æ–≥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –±–æ—Ç–æ–º —á–µ—Ä–µ–∑ —Å—Ç–æ—Ä–æ–Ω–Ω–∏–π API.

<b>–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ:</b> –ù–∞—à –±–æ—Ç —Ç–∞–∫–∂–µ –ø–æ–¥–ø–∞–¥–∞–µ—Ç –ø–æ–¥ –¥–µ–π—Å—Ç–≤–∏–µ <b>–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–∏ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ Telegram –¥–ª—è –±–æ—Ç–æ–≤</b>. –û–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å –Ω–µ–π –º–æ–∂–Ω–æ –ø–æ —Å—Å—ã–ª–∫–µ: <a href="https://telegram.org/privacy-tpa">https://telegram.org/privacy-tpa</a>.

–î–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–≤—è–∂–∏—Ç–µ—Å—å —Å —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞–º–∏ –±–æ—Ç–∞.
"""

# Gemini API –∫–æ–Ω—Ñ–∏–≥
API_KEYS = []
for i in [1, 2]:
    key = os.getenv(f"GEMINI_API_KEY_{i}")
    if key:
        API_KEYS.append(key)

if not API_KEYS:
    raise RuntimeError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è GEMINI_API_KEY_1 –∏–ª–∏ GEMINI_API_KEY_2")

MODELS = [
    "gemini-1.5-pro-latest", "gemini-1.5-flash-latest",
]
MAX_HISTORY = 20
current_key_idx = 0
current_model_idx = 0
available_models: List[str] = MODELS.copy()
last_model_check_ts: float = 0.0

# ----------- –ü–µ—Ä—Å–æ–Ω–∞ –±–æ—Ç–∞ –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è LLM -----------
BOT_PERSONA_PROMPT = """
–¢—ã - —É–º–Ω—ã–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∏–º–µ–Ω–∏ –°–∏–≥–º–æ–∏–¥–∞.
–ù–µ —É–ø–æ–º–∏–Ω–∞–π, —á—Ç–æ —Ç—ã Google, Gemini –∏–ª–∏ –±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å.
–§–æ—Ä–º–∞—Ç–∏—Ä—É–π —Å–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É—è HTML-—Ç–µ–≥–∏, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Å Telegram.
–ò—Å–ø–æ–ª—å–∑—É–π <b>–¥–ª—è –∂–∏—Ä–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞</b>, <i>–¥–ª—è –∫—É—Ä—Å–∏–≤–∞</i>, <u>–¥–ª—è –ø–æ–¥—á–µ—Ä–∫–Ω—É—Ç–æ–≥–æ</u>, <s>–¥–ª—è –∑–∞—á–µ—Ä–∫–Ω—É—Ç–æ–≥–æ</s>, <spoiler>–¥–ª—è —Å–ø–æ–π–ª–µ—Ä–æ–≤</spoiler>, <code>–¥–ª—è –º–æ–Ω–æ—à–∏—Ä–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞</code> –∏ <pre>–¥–ª—è –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞</pre>.
–î–ª—è —Å—Å—ã–ª–æ–∫ –∏—Å–ø–æ–ª—å–∑—É–π <a href="URL">—Ç–µ–∫—Å—Ç —Å—Å—ã–ª–∫–∏</a>.
"""

# ---------- –õ–æ–≥–∏ ----------
logging.basicConfig(
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
    level=logging.INFO
)
log = logging.getLogger("wizardbot")

# ---------- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ----------
ADMIN_ID = os.getenv("ADMIN_ID")
DATA_DIR = "data"
HISTORY_FILE = os.path.join(DATA_DIR, "history.json")
CONFIGS_FILE = os.path.join(DATA_DIR, "configs.json")

# ---------- –ö–æ–Ω—Ñ–∏–≥ –Ω–∞ —á–∞—Ç ----------
@dataclass
class ChatConfig:
    autopost_enabled: bool = False
    interval: int = 14400
    min_messages: int = 10
    msg_size: str = ""
    last_post_ts: float = 0.0
    new_msg_counter: int = 0

configs: Dict[int, ChatConfig] = {}
history: Dict[int, List[ContentType]] = {}

# ---------- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ----------
def load_data():
    global history, configs
    os.makedirs(DATA_DIR, exist_ok=True)
    try:
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            history = {int(k): v for k, v in json.load(f).items()}
            log.info(f"Loaded {len(history)} chat histories.")
    except (FileNotFoundError, json.JSONDecodeError):
        history = {}
    try:
        with open(CONFIGS_FILE, 'r', encoding='utf-8') as f:
            configs = {int(k): ChatConfig(**v) for k, v in json.load(f).items()}
            log.info(f"Loaded {len(configs)} chat configs.")
    except (FileNotFoundError, json.JSONDecodeError):
        configs = {}

def save_data():
    log.info("Saving data...")
    os.makedirs(DATA_DIR, exist_ok=True)
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        configs_to_save = {cid: asdict(cfg) for cid, cfg in configs.items()}
        with open(CONFIGS_FILE, 'w', encoding='utf-8') as f:
            json.dump(configs_to_save, f, ensure_ascii=False, indent=2)
        log.info("Data saved.")
    except Exception as e:
        log.error(f"Failed to save data: {e}", exc_info=True)

async def save_data_job(context: CallbackContext):
    await asyncio.get_running_loop().run_in_executor(None, save_data)

# ---------- –í—Å–ø–æ–º–æ–≥–∞–ª–∫–∏ ----------
def get_cfg(chat_id: int) -> ChatConfig:
    if chat_id not in configs:
        configs[chat_id] = ChatConfig()
    return configs[chat_id]

def llm_request(chat_id: int, prompt_parts: List[PartType]) -> Tuple[Optional[str], str, Optional[FunctionCall]]:
    global current_key_idx, current_model_idx
    chat_history = history.get(chat_id, [])

    if len(chat_history) > MAX_HISTORY:
        log.info(f"Summarizing history for chat {chat_id}...")
        try:
            summary_prompt = "Summarize this conversation in a concise paragraph for context."
            summary_model = genai.GenerativeModel("gemini-1.5-flash-latest", api_key=API_KEYS[current_key_idx])
            response = summary_model.generate_content(chat_history + [{'role': 'user', 'parts': [{'text': summary_prompt}]}])
            summary = response.text
            new_history = [
                {'role': 'user', 'parts': [{'text': "Start of conversation."}]},
                {'role': 'model', 'parts': [{'text': f"Previously discussed: {summary}"}]}
            ]
            history[chat_id] = new_history
            chat_history = new_history
        except Exception as e:
            log.error(f"History summarization failed for chat {chat_id}: {e}")
            history[chat_id] = chat_history[-MAX_HISTORY:]
            chat_history = history[chat_id]

    models_to_try = available_models if available_models else MODELS
    for model_idx_offset in range(len(models_to_try)):
        model_idx = (current_model_idx + model_idx_offset) % len(models_to_try)
        model_name = models_to_try[model_idx]
        for key_try in range(len(API_KEYS)):
            key_idx = (current_key_idx + key_try) % len(API_KEYS)
            try:
                genai.configure(api_key=API_KEYS[key_idx])
                tools = [Tool(function_declarations=[{
                    "name": "generate_image",
                    "description": "Generates an image from a text description. Use for explicit requests to 'draw', 'create an image', etc.",
                    "parameters": {"type": "OBJECT", "properties": {"prompt": {"type": "STRING", "description": "The image description."}}, "required": ["prompt"]}
                }])]
                model = genai.GenerativeModel(model_name, tools=tools, system_instruction=BOT_PERSONA_PROMPT)
                contents = chat_history + [{'role': 'user', 'parts': prompt_parts}]
                response = model.generate_content(contents)
                
                if response.candidates and response.candidates[0].content.parts[0].function_call:
                    return None, model_name, response.candidates[0].content.parts[0].function_call
                
                answer = response.text
                history[chat_id] = contents + [{'role': 'model', 'parts': [{'text': answer}]}]
                current_key_idx, current_model_idx = key_idx, model_idx
                return answer, model_name, None
            except Exception as e:
                if "rate limit" in str(e).lower():
                    log.info(f"Rate limit on key {key_idx+1}, model {model_name}. Trying next...")
                else:
                    log.warning(f"Request failed: key {key_idx+1}, model {model_name}: {e}")
    raise Exception("All API keys/models failed")

async def llm_generate_image(prompt: str) -> Tuple[Optional[bytes], str]:
    global current_key_idx
    model_name = "gemini-1.5-flash-latest"
    for key_try in range(len(API_KEYS)):
        key_idx = (current_key_idx + key_try) % len(API_KEYS)
        try:
            genai.configure(api_key=API_KEYS[key_idx])
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(f"Draw: {prompt}", generation_config={"response_mime_type": "image/png"})
            if response.parts:
                current_key_idx = key_idx
                return response.parts[0].inline_data.data, model_name
        except Exception as e:
            log.warning(f"Image generation failed on key {key_idx+1}: {e}")
    return None, model_name

def check_available_models() -> List[str]:
    global available_models, last_model_check_ts
    log.info("Checking available models...")
    working_models = []
    for model_name in MODELS:
        for api_key in API_KEYS:
            try:
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel(model_name)
                _ = model.generate_content("hi").text
                working_models.append(model_name)
                log.info(f"Model {model_name} is available")
                break
            except Exception:
                continue
    if working_models:
        available_models = working_models
        last_model_check_ts = time.time()
        log.info(f"Available models updated: {working_models}")
    else:
        available_models = MODELS.copy()
    return available_models

async def is_admin(update: Update, context: ContextTypes.DEFAULT_TYPE) -> bool:
    if str(update.effective_user.id) == ADMIN_ID:
        return True
    await update.message.reply_text("–≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
    return False

def answer_size_prompt(size: str) -> str:
    return {"small": "–ö—Ä–∞—Ç–∫–æ:", "medium": "–û—Ç–≤–µ—Ç—å —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ:", "large": "–û—Ç–≤–µ—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–¥—Ä–æ–±–Ω–æ:"}.get(size, "")

def split_long_message(text: str, max_length: int = 4096) -> List[str]:
    if len(text) <= max_length:
        return [text]
    parts, current = [], ""
    # TODO: More intelligent splitting that respects HTML tags
    for line in text.split("\n"):
        if len(current) + len(line) + 1 <= max_length:
            current += (line + "\n")
        else:
            if current: parts.append(current.strip())
            current = line
    if current: parts.append(current.strip())
    return parts

# ---------- –ö–æ–º–∞–Ω–¥—ã ----------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("üëã –Ø Gemini –±–æ—Ç. /help ‚Äì —Å–ø—Ä–∞–≤–∫–∞\n\n"
                                    "‚ö†Ô∏è <b>–í–∞–∂–Ω–æ:</b> –í–∞—à–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –º–µ–¥–∏–∞—Ñ–∞–π–ª—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ Google Gemini API. /privacy",
                                    parse_mode=ParseMode.HTML)

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("<b>–ö–æ–º–∞–Ω–¥—ã:</b>\n"
                                    "/settings ‚Äì –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n"
                                    "/autopost on|off ‚Äì –≤–∫–ª/–≤—ã–∫–ª –∞–≤—Ç–æ–ø–æ—Å—Ç—ã (–∞–¥–º–∏–Ω)\n"
                                    "/set_interval &lt;—Å–µ–∫&gt; ‚Äì –∏–Ω—Ç–µ—Ä–≤–∞–ª –∞–≤—Ç–æ–ø–æ—Å—Ç–∞ (–∞–¥–º–∏–Ω)\n"
                                    "/set_minmsgs &lt;n&gt; ‚Äì –º–∏–Ω–∏–º—É–º —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–≤—Ç–æ–ø–æ—Å—Ç–∞ (–∞–¥–º–∏–Ω)\n"
                                    "/set_msgsize &lt;s|m|l&gt; ‚Äì —Ä–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–æ–≤ (–∞–¥–º–∏–Ω)\n"
                                    "/draw &lt;–æ–ø–∏—Å–∞–Ω–∏–µ&gt; ‚Äì –Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n"
                                    "/reset ‚Äì –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞\n"
                                    "/privacy ‚Äì –ø–æ–ª–∏—Ç–∏–∫–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏",
                                    parse_mode=ParseMode.HTML)

async def privacy_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(PRIVACY_POLICY_TEXT, parse_mode=ParseMode.HTML, disable_web_page_preview=True)

async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    history.pop(update.effective_chat.id, None)
    await update.message.reply_text("–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞ ‚úÖ")
    
async def delete_data(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not await is_admin(update, context): return
    if not context.args: return await update.message.reply_text("–£–∫–∞–∂–∏—Ç–µ ID —á–∞—Ç–∞.")
    try:
        target_id = int(context.args[0])
        history.pop(target_id, None)
        configs.pop(target_id, None)
        await update.message.reply_text(f"–î–∞–Ω–Ω—ã–µ –¥–ª—è ID {target_id} —É–¥–∞–ª–µ–Ω—ã.")
    except (ValueError, IndexError):
        await update.message.reply_text("–ù–µ–≤–µ—Ä–Ω—ã–π ID.")

async def settings_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    cfg = get_cfg(update.effective_chat.id)
    await update.message.reply_text(f"<b>–ê–≤—Ç–æ–ø–æ—Å—Ç—ã:</b> {'–≤–∫–ª' if cfg.autopost_enabled else '–≤—ã–∫–ª'}.\n"
                                    f"<b>–ò–Ω—Ç–µ—Ä–≤–∞–ª:</b> {cfg.interval} —Å–µ–∫, <b>–º–∏–Ω. —Å–æ–æ–±—â–µ–Ω–∏–π:</b> {cfg.min_messages}.\n"
                                    f"<b>–†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–æ–≤:</b> {cfg.msg_size or 'default'}.",
                                    parse_mode=ParseMode.HTML)

async def autopost_switch(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not await is_admin(update, context): return
    if not context.args or context.args[0] not in {"on", "off"}: return await update.message.reply_text("–ü—Ä–∏–º–µ—Ä: /autopost on")
    cfg = get_cfg(update.effective_chat.id)
    cfg.autopost_enabled = (context.args[0] == "on")
    await update.message.reply_text(f"–ê–≤—Ç–æ–ø–æ—Å—Ç—ã {'–≤–∫–ª—é—á–µ–Ω—ã' if cfg.autopost_enabled else '–≤—ã–∫–ª—é—á–µ–Ω—ã'}.")

async def set_interval(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not await is_admin(update, context): return
    try:
        cfg = get_cfg(update.effective_chat.id)
        cfg.interval = max(300, int(context.args[0]))
        await update.message.reply_text(f"–ò–Ω—Ç–µ—Ä–≤–∞–ª –∞–≤—Ç–æ–ø–æ—Å—Ç–∞ = {cfg.interval} —Å–µ–∫.")
    except (IndexError, ValueError):
        await update.message.reply_text("–ü—Ä–∏–º–µ—Ä: /set_interval 7200")

async def set_minmsgs(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not await is_admin(update, context): return
    try:
        cfg = get_cfg(update.effective_chat.id)
        cfg.min_messages = max(1, int(context.args[0]))
        await update.message.reply_text(f"–ú–∏–Ω–∏–º—É–º —Å–æ–æ–±—â–µ–Ω–∏–π = {cfg.min_messages}.")
    except (IndexError, ValueError):
        await update.message.reply_text("–ü—Ä–∏–º–µ—Ä: /set_minmsgs 10")

async def set_msgsize(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not await is_admin(update, context): return
    size = (context.args or [""])[0].lower()
    if size not in {"small", "medium", "large", "s", "m", "l", ""}:
        return await update.message.reply_text("–í–∞—Ä–∏–∞–Ω—Ç—ã: small, medium, large –∏–ª–∏ –ø—É—Å—Ç–æ (default)")
    cfg = get_cfg(update.effective_chat.id)
    if size in {"s", "m", "l"}:
        cfg.msg_size = size
    elif size:
        cfg.msg_size = size[0]
    else:
        cfg.msg_size = ""
    await update.message.reply_text(f"–†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–æ–≤ = {cfg.msg_size or 'default'}.")

async def draw_image_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.args: return await update.message.reply_text("–ü—Ä–∏–º–µ—Ä: /draw –∫–æ—Ç –≤ —Å–∫–∞—Ñ–∞–Ω–¥—Ä–µ")
    await generate_and_send_image(update, context, ' '.join(context.args))

async def generate_and_send_image(update: Update, context: ContextTypes.DEFAULT_TYPE, prompt: str):
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="upload_photo")
    try:
        image_bytes, model_used = await asyncio.get_running_loop().run_in_executor(None, llm_generate_image, prompt)
        if image_bytes:
            model_display = model_used.replace("gemini-", "").replace("-latest", "").title()
            caption = f"üé® ¬´{prompt}¬ª\n\n<b>Generated by {model_display}</b>"
            await update.message.reply_photo(photo=image_bytes, caption=caption, parse_mode=ParseMode.HTML)
        else:
            await update.message.reply_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
    except Exception as e:
        log.exception(e)
        await update.message.reply_text("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")

# ---------- –û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ ----------
async def send_bot_response(update: Update, context: ContextTypes.DEFAULT_TYPE, chat_id: int, prompt_parts: List[PartType]):
    await context.bot.send_chat_action(chat_id=chat_id, action="typing")
    try:
        reply, model_used, function_call = await asyncio.get_running_loop().run_in_executor(None, llm_request, chat_id, prompt_parts)

        if function_call and function_call.name == "generate_image":
            return await generate_and_send_image(update, context, function_call.args.get("prompt", ""))

        if reply:
            model_display = model_used.replace("gemini-", "").replace("-latest", "").title()
            full_reply = f"<b>{model_display}</b>\n\n{reply}"
            for chunk in split_long_message(full_reply):
                try:
                    await update.message.reply_text(chunk, parse_mode=ParseMode.HTML, disable_web_page_preview=True)
                except BadRequest as e:
                    log.warning(f"HTML parse failed, sending plain text. Error: {e}")
                    await update.message.reply_text(chunk, disable_web_page_preview=True)
    except Exception as e:
        log.exception(e)
        await update.message.reply_text("‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏.")

async def handle_text_and_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message: return
    chat_id = update.effective_chat.id
    text = update.message.text or update.message.caption or ""

    if update.message.chat.type in (ChatType.GROUP, ChatType.SUPERGROUP):
        bot_mentioned = any(
            text[e.offset:e.offset+e.length].lstrip('@').lower() == context.bot.username.lower()
            for e in (update.message.entities or []) if e.type == MessageEntityType.MENTION
        )
        is_reply_to_bot = update.message.reply_to_message and update.message.reply_to_message.from_user.username == context.bot.username
        
        if not (bot_mentioned or is_reply_to_bot):
            get_cfg(chat_id).new_msg_counter += 1
            return
        
        for e in reversed(update.message.entities or []):
            if e.type == MessageEntityType.MENTION and text[e.offset:e.offset+e.length].lstrip('@').lower() == context.bot.username.lower():
                text = (text[:e.offset] + text[e.offset+e.length:]).strip()
    
    cfg = get_cfg(chat_id)
    cfg.new_msg_counter += 1
    prompt_parts = []
    if text: prompt_parts.append(answer_size_prompt(cfg.msg_size) + text)
    if update.message.photo:
        file = await update.message.photo[-1].get_file()
        file_bytes = await file.download_as_bytearray()
        prompt_parts.insert(0, Image.open(io.BytesIO(file_bytes)))

    if not prompt_parts: return
    await send_bot_response(update, context, chat_id, prompt_parts)

async def handle_media(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message: return
    media, prompt = None, ""
    if update.message.voice: media, prompt = update.message.voice, "–†–∞—Å—à–∏—Ñ—Ä—É–π —ç—Ç–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:"
    elif update.message.video: media, prompt = update.message.video, "–û–ø–∏—à–∏, —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —ç—Ç–æ–º –≤–∏–¥–µ–æ:"
    elif update.message.video_note: media, prompt = update.message.video_note, "–û–ø–∏—à–∏ —ç—Ç–æ –≤–∏–¥–µ–æ-—Å–æ–æ–±—â–µ–Ω–∏–µ:"
    
    if not media: return
    chat_id = update.effective_chat.id
    await context.bot.send_chat_action(chat_id=chat_id, action="typing")
    file = await media.get_file()
    prompt_parts = [{"mime_type": file.mime_type, "data": await file.download_as_bytearray()}, {"text": prompt}]
    await send_bot_response(update, context, chat_id, prompt_parts)

# ---------- –ó–∞–¥–∞—á–∏ ----------
async def check_models_job(context: CallbackContext):
    await asyncio.get_running_loop().run_in_executor(None, check_available_models)

async def autopost_job(context: CallbackContext):
    for chat_id, cfg in list(configs.items()):
        if not (cfg.autopost_enabled and cfg.new_msg_counter >= cfg.min_messages and time.time() - cfg.last_post_ts > cfg.interval):
            continue
        prompt = f"–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ö {cfg.new_msg_counter} —Å–æ–æ–±—â–µ–Ω–∏–π —á–∞—Ç–∞. –í—ã–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã."
        log.info(f"Autopost in chat {chat_id}")
        try:
            summary, model_used, _ = await asyncio.get_running_loop().run_in_executor(None, llm_request, chat_id, [{"text": prompt}])
            if summary:
                model_display = model_used.replace("gemini-", "").replace("-latest", "").title()
                message_text = f"üì∞ <b>–ê–≤—Ç–æ–¥–∞–π–¥–∂–µ—Å—Ç ({model_display}):</b>\n{summary}"
                for chunk in split_long_message(message_text):
                    try:
                        await context.bot.send_message(chat_id, chunk, parse_mode=ParseMode.HTML)
                    except BadRequest:
                        await context.bot.send_message(chat_id, chunk)
                cfg.last_post_ts, cfg.new_msg_counter = time.time(), 0
        except Exception as e:
            log.error(f"Autopost failed for chat {chat_id}: {e}")

# ---------- Main ----------
def main():
    load_data()
    atexit.register(save_data)

    token, admin_id = os.getenv("TG_TOKEN"), os.getenv("ADMIN_ID")
    if not token or not admin_id: raise RuntimeError("TG_TOKEN –∏ ADMIN_ID –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
    
    try:
        bot_info = requests.get(f"https://api.telegram.org/bot{token}/getMe").json().get('result', {})
        if not bot_info.get('username'): raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å username –±–æ—Ç–∞.")
        log.info(f"Bot Username: @{bot_info['username']}")
    except Exception as e:
        raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –±–æ—Ç–µ: {e}")

    app = ApplicationBuilder().token(token).build()
    app.bot.username = bot_info['username']

    command_handlers = {
        "start": start, "help": help_cmd, "privacy": privacy_cmd,
        "reset": reset, "draw": draw_image_cmd, "settings": settings_cmd,
        "delete_data": delete_data, "autopost": autopost_switch,
        "set_interval": set_interval, "set_minmsgs": set_minmsgs,
        "set_msgsize": set_msgsize
    }
    for command, callback in command_handlers.items():
        app.add_handler(CommandHandler(command, callback))
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–ª–∏–∞—Å—ã –¥–ª—è –≥—Ä—É–ø–ø (e.g. /draw@botname)
        app.add_handler(CommandHandler(f"{command}_{app.bot.username}", callback))

    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_and_photo))
    app.add_handler(MessageHandler(filters.PHOTO, handle_text_and_photo))
    app.add_handler(MessageHandler(filters.VOICE | filters.VIDEO | filters.VIDEO_NOTE, handle_media))

    if app.job_queue:
        app.job_queue.run_repeating(save_data_job, 60, 60)
        app.job_queue.run_repeating(check_models_job, 14400, 60)
        app.job_queue.run_repeating(autopost_job, 60, 60)
        log.info("JobQueue initialized")

    threading.Thread(target=lambda: flask_app.run(host='0.0.0.0', port=int(os.getenv("PORT", 10000))), daemon=True).start()
    log.info("Flask app started")
    log.info("Bot started üöÄ")
    app.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()